{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Notation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A linear model is simply a model which weights each input and then adds all the weighted inputs together for a prediction.\n",
    "\n",
    "It is the classic $y=mx+b$ from school."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to properly notate a linear model, we can think of it as a number of weighted scalars\n",
    "$$ \\hat{y}= \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + ... \\theta_n x_n $$\n",
    "Where \n",
    "* $\\theta_0$ is the bias term\n",
    "* $\\theta$ is the weight or model parameter\n",
    "* $n$ is the number of features\n",
    "* $x$ is the feature value\n",
    "\n",
    "*note* $\\theta_0$ actually does have an $x_0$ with it, but $x_0 = 1$ and thus it is dropped\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can actually take these scalars and combine them into vectors\n",
    "\n",
    "so $x_1, x_2, ... x_n$ can be represented as **x**\n",
    "$$ \\mathbf{x} = \\begin{bmatrix} x_1 \\\\ x_2 \\\\ \\vdots  \\\\ x_n \\end{bmatrix}  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do the same things with the weights, assign them to a vector $\\boldsymbol{\\theta}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our new notation for a linear model then becomes:\n",
    "\n",
    "$$ \\hat{y}=h_\\boldsymbol{\\theta} (\\mathbf{x}) = \\boldsymbol{\\theta} \\cdot \\mathbf{x} $$\n",
    "\n",
    "*note* if the vectors are *column vectors* as is common with machine learning vectors, then the combination is $\\boldsymbol{\\theta}^\\intercal \\mathbf{x}$. This way we make the parameters a row vector and we can do a matrix multiplication. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A linear model is the equation for a line that minimizes prediction error. We can measure this with the mean squared error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our cost function that needs to be minimized is:\n",
    "$$(\\frac{1}{m})\\sum_{i=1}^{m}(\\boldsymbol{\\theta}^\\intercal \\mathbf{x}^{i} - y^{i})^{2} $$ or $$ MSE(\\boldsymbol{\\theta})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can directly calculate the $\\theta$s that give us the lowest MSE using:\n",
    "$$ \\hat{\\boldsymbol{\\theta}} = (\\mathbf{X}^{\\intercal} \\mathbf{X})^{-1} \\mathbf{X}^{\\intercal} \\mathbf{y} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = 2 * np.random.rand(100,1)\n",
    "y = 4 + 3 * X + np.random.randn(100,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy gives us inv() to get the inverse of a matrix. Used as np.linalg.inv()\n",
    "# numpy gives us dot() for dot products\n",
    "\n",
    "# first we need to add the bias term\n",
    "bias_array = np.ones((100,1)) #one for each instance/record\n",
    "bias_array[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.26076609],\n",
       "       [1.        , 1.33482468],\n",
       "       [1.        , 0.12550273],\n",
       "       [1.        , 0.82929584],\n",
       "       [1.        , 1.16814901]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_b = np.c_[bias_array,X]\n",
    "X_b[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.02918604],\n",
       "       [2.90252382]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_theta = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y)\n",
    "best_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that the correct answer should be \n",
    "* bias term of 4\n",
    "* $\\theta$ of 3\n",
    "\n",
    "(since we set $y$ to that earlier).  So this got very close."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.02918604],\n",
       "       [9.83423368]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we use those to make a prediction\n",
    "\n",
    "X_test = np.array([[0],[2]])\n",
    "X_test_b = np.c_[np.ones((2,1)), X_test]\n",
    "y_predict = X_test_b.dot(best_theta)\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
